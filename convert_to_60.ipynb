{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit ('env')",
   "display_name": "Python 3.8.6 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "2b72526ed668422a4c42010915fcc77e6aba1ae6946ec448acf614b0bbb60243"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from flow_models import *\n",
    "from model_trainer import AnimeModel\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_size = (960,540)\n",
    "interp_ratio = [0.5]\n",
    "model_f = hr_3_2_16\n",
    "weight_dir = 'savedmodels/hr3216_real_flowcheck6/20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input((frame_size[1],frame_size[0],6))\n",
    "anime_model = AnimeModel(inputs, model_f, interp_ratio)\n",
    "anime_model.load_weights(weight_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_dir = Path('data/cut')\n",
    "vid_paths = [str(vid_dir/vn) for vn in os.listdir(vid_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(vid_paths[0])\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "writer = cv2.VideoWriter(f'{vid_paths[0]}_interp.mp4',fourcc,60,frame_size)\n",
    "i = 0\n",
    "ret, frame = cap.read()\n",
    "for i in trange(600):\n",
    "    if not cap.isOpened():\n",
    "        break\n",
    "    if ret:\n",
    "        frame0 = frame\n",
    "    else:\n",
    "        break\n",
    "    ret, _ = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame1 = frame\n",
    "    else:\n",
    "        break\n",
    "    frame0_resized = cv2.resize(frame0, dsize=frame_size)\n",
    "    frame1_resized = cv2.resize(frame1, dsize=frame_size)\n",
    "    concated = np.concatenate([frame0_resized,frame1_resized],axis=-1).astype(np.float32)/ 255.0\n",
    "    interped = anime_model(concated[np.newaxis,...])[0]\n",
    "    interped = np.round(np.clip(interped, 0, 1) * 255).astype(np.uint8)\n",
    "    writer.write(frame0_resized)\n",
    "    writer.write(interped)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}